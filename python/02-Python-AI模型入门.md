# 模型区分
在过去几年出现的类似阿尔法go这样的 AI, 图片识别，人物识别等, 是属于特定任务的传统机器学习模型，它相对大语言模型更简单，而大语言模型是基于深度学习的通用语言模型，两者有本质的区别


# 大语言模型 （Large Language Model，LLM）
LLM 是基于深度学习的预训练模型，如 Transformer 架构，通过在大量文本数据上进行无监督训练，学习自然语言的内在特征和结构。它能够处理各种自然语言任务，如文本生成、翻译、问答等。GPT 和 Claude 等模型为代表。它更像是使用推理来生成内容，它不擅长数学计算，但是运行它却要更高的算力。大部分情况下，它依靠自身模型来推导结果，除了一些非常专业的领域才需要将它与传统深度学习模型结合使用，所以不能一口判定大语言模型底层就是调用传统机器学习模型。

> LLM 主要理解文本的语义和上下文，然后推理并生成结果

# llama-3.1-70b-instruct
llama 指模型的名字
3.1是模型的版本
70b是模型的参数量70亿
instruct 该模型经过指令微调

> 模型的对比，不能只从名字上的参数量来评定强大与否，还受具体需求、可用的计算资源，模型性能, 训练数据的质量、训练方法、特定任务的适应性等


# 指令微调
指令微调是一种训练技术，旨在提高模型对特定指令或提示的响应能力。经过指令微调的模型通常能更好地理解和执行用户的具体指令，使其在对话和任务执行中表现得更加自然和精确。
这种模型通常更适合用于对话系统、问答任务、以及需要遵循特定指令的场景。相比未经指令微调的基础模型，"-instruct" 版本的模型往往在实际应用中表现更好。